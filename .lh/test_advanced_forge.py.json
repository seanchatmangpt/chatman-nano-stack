{
    "sourceFile": "test_advanced_forge.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1753291110329,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1753291120944,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,275 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Test Advanced Forge Features\n+Comprehensive testing of quality controls and DSPy agents\n+\"\"\"\n+\n+import json\n+from pathlib import Path\n+\n+from rich.console import Console\n+from rich.panel import Panel\n+\n+from dspy_ontology_agents import CollaborativeOntologyOptimizer, OntologyAgentSwarm\n+from ontology_quality_control import OntologyQualityController\n+\n+console = Console()\n+\n+def test_quality_control():\n+    \"\"\"Test quality control system\"\"\"\n+    console.print(Panel.fit(\n+        \"[bold blue]Testing Quality Control System[/bold blue]\",\n+        border_style=\"blue\"\n+    ))\n+\n+    # Test with existing real-time ontologies\n+    realtime_dir = Path(\"ontologies/generated/realtime\")\n+    if not realtime_dir.exists():\n+        console.print(\"[red]Real-time ontologies not found - run real-time generation first[/red]\")\n+        return\n+\n+    qc = OntologyQualityController()\n+\n+    console.print(\"üîç Running comprehensive validation...\")\n+    report = qc.validate_ontology_suite(realtime_dir, \"realtime\")\n+\n+    console.print(f\"üìä Quality Score: {report.metrics['quality_score']:.1f}/100\")\n+    console.print(f\"üî¥ Critical Issues: {report.critical_count}\")\n+    console.print(f\"üü° Warnings: {report.warning_count}\")\n+    console.print(f\"‚úÖ Passed: {'Yes' if report.passed else 'No'}\")\n+\n+    # Test optimization\n+    if report.issues:\n+        console.print(\"\\n‚ö° Testing ontology optimization...\")\n+\n+        core_files = list(realtime_dir.glob(\"*core*.ttl\"))\n+        if core_files:\n+            try:\n+                optimized_content, optimizations = qc.optimize_ontology(\n+                    core_files[0],\n+                    \"trading\",\n+                    {\"tick_compliance\": 8}\n+                )\n+\n+                console.print(f\"üìà Applied {len(optimizations)} optimizations:\")\n+                for opt in optimizations:\n+                    console.print(f\"  ‚Ä¢ {opt}\")\n+\n+            except Exception as e:\n+                console.print(f\"[red]Optimization failed: {str(e)}[/red]\")\n+\n+    return report\n+\n+def test_agent_swarm():\n+    \"\"\"Test multi-agent analysis system\"\"\"\n+    console.print(Panel.fit(\n+        \"[bold green]Testing Multi-Agent Swarm[/bold green]\",\n+        border_style=\"green\"\n+    ))\n+\n+    # Test with trading ontologies\n+    trading_dir = Path(\"ontologies/meta_generated/trading\")\n+    if not trading_dir.exists():\n+        console.print(\"[red]Trading ontologies not found - generate first[/red]\")\n+        return\n+\n+    swarm = OntologyAgentSwarm()\n+\n+    requirements = {\n+        \"performance_requirements\": {\"tick_compliance\": 8},\n+        \"compliance_standards\": [\"MiFID II\"],\n+        \"domain_patterns\": {\"ultra_low_latency\": True},\n+        \"hardware_constraints\": {\"target_latency_ns\": 100}\n+    }\n+\n+    console.print(\"ü§ñ Running multi-agent analysis...\")\n+    try:\n+        analysis = swarm.analyze_ontology_suite(trading_dir, \"trading\", requirements)\n+\n+        console.print(f\"üéØ Domain Accuracy: {analysis['domain_analysis']['accuracy_score']:.1f}%\")\n+        console.print(f\"‚ö° Performance Score: {analysis['performance_analysis']['performance_score']:.1f}%\")\n+        console.print(f\"üìã Compliance Score: {analysis['compliance_analysis']['compliance_score']:.1f}%\")\n+        console.print(f\"üèÜ Overall Quality: {analysis['quality_synthesis']['overall_quality_score']:.1f}%\")\n+\n+        # Show agent communications\n+        console.print(f\"\\nüí¨ Agent Messages: {len(analysis['message_history'])}\")\n+        for msg in analysis['message_history'][:3]:  # Show first 3\n+            console.print(f\"  {msg['from_agent']} ‚Üí {msg['to_agent']}: {msg['content']}\")\n+\n+        # Generate collaboration report\n+        report = swarm.generate_agent_collaboration_report()\n+        report_file = Path(\"agent_collaboration_report.md\")\n+        report_file.write_text(report)\n+        console.print(f\"üìÑ Collaboration report saved to: {report_file}\")\n+\n+        return analysis\n+\n+    except Exception as e:\n+        console.print(f\"[red]Agent swarm failed: {str(e)}[/red]\")\n+        return None\n+\n+def test_collaborative_optimization():\n+    \"\"\"Test collaborative optimization\"\"\"\n+    console.print(Panel.fit(\n+        \"[bold yellow]Testing Collaborative Optimization[/bold yellow]\",\n+        border_style=\"yellow\"\n+    ))\n+\n+    trading_dir = Path(\"ontologies/meta_generated/trading\")\n+    if not trading_dir.exists():\n+        console.print(\"[red]Trading ontologies not found[/red]\")\n+        return\n+\n+    optimizer = CollaborativeOntologyOptimizer()\n+\n+    requirements = {\n+        \"performance_requirements\": {\"tick_compliance\": 8},\n+        \"compliance_standards\": [\"MiFID II\"],\n+        \"quality_threshold\": 90.0\n+    }\n+\n+    console.print(\"üîÑ Running iterative optimization...\")\n+    try:\n+        optimization_result = optimizer.iterative_optimization(\n+            trading_dir, \"trading\", requirements, max_iterations=2\n+        )\n+\n+        console.print(f\"üéØ Iterations Completed: {optimization_result['iterations_completed']}\")\n+        console.print(f\"üìà Final Quality Score: {optimization_result['final_quality_score']:.1f}%\")\n+\n+        # Show optimization history\n+        for iteration in optimization_result['optimization_history']:\n+            if 'error' not in iteration:\n+                console.print(f\"  Iteration {iteration['iteration']}: \"\n+                            f\"{iteration['quality_score_before']:.1f}% ‚Üí \"\n+                            f\"{iteration['quality_score_after']:.1f}%\")\n+\n+        return optimization_result\n+\n+    except Exception as e:\n+        console.print(f\"[red]Collaborative optimization failed: {str(e)}[/red]\")\n+        return None\n+\n+def test_advanced_commands():\n+    \"\"\"Test advanced CLI commands\"\"\"\n+    console.print(Panel.fit(\n+        \"[bold magenta]Testing Advanced CLI Commands[/bold magenta]\",\n+        border_style=\"magenta\"\n+    ))\n+\n+    # Test validation command\n+    console.print(\"üîç Testing validation command...\")\n+\n+    # Create test manifest for validation\n+    test_dir = Path(\"test_ontologies\")\n+    test_dir.mkdir(exist_ok=True)\n+\n+    # Create simple test ontology\n+    test_ttl = test_dir / \"test.ttl\"\n+    test_ttl.write_text(\"\"\"\n+@prefix : <http://test.io#> .\n+@prefix owl: <http://www.w3.org/2002/07/owl#> .\n+@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n+\n+:TestClass a owl:Class ;\n+    rdfs:label \"Test Class\" .\n+\n+:testProperty a owl:DatatypeProperty ;\n+    rdfs:domain :TestClass .\n+\"\"\")\n+\n+    # Create manifest\n+    manifest = {\n+        \"domain\": \"test\",\n+        \"name\": \"Test Ontology\",\n+        \"performance_requirements\": {\"tick_compliance\": 8},\n+        \"compliance_standards\": []\n+    }\n+\n+    manifest_file = test_dir / \"manifest.json\"\n+    with open(manifest_file, 'w') as f:\n+        json.dump(manifest, f, indent=2)\n+\n+    console.print(f\"‚úÖ Created test ontology in {test_dir}\")\n+\n+    # Show what advanced commands would do\n+    console.print(\"\\nüìã Available Advanced Commands:\")\n+    commands = [\n+        (\"validate\", \"Comprehensive quality validation\"),\n+        (\"optimize\", \"DSPy-powered optimization\"),\n+        (\"audit\", \"Compliance auditing\"),\n+        (\"benchmark\", \"Advanced benchmarking\"),\n+        (\"explain\", \"AI-powered explanation\"),\n+        (\"compare\", \"Multi-dimensional comparison\"),\n+        (\"deploy\", \"Quality-gated deployment\")\n+    ]\n+\n+    for cmd, desc in commands:\n+        console.print(f\"  ‚Ä¢ {cmd}: {desc}\")\n+\n+def run_comprehensive_test():\n+    \"\"\"Run comprehensive test suite\"\"\"\n+    console.print(Panel.fit(\n+        \"[bold red]üöÄ Advanced Forge Comprehensive Test Suite[/bold red]\",\n+        border_style=\"red\"\n+    ))\n+\n+    results = {}\n+\n+    # Test 1: Quality Control\n+    try:\n+        results['quality_control'] = test_quality_control()\n+        console.print(\"[green]‚úÖ Quality Control Test: PASSED[/green]\")\n+    except Exception as e:\n+        console.print(f\"[red]‚ùå Quality Control Test: FAILED - {str(e)}[/red]\")\n+        results['quality_control'] = None\n+\n+    console.print()\n+\n+    # Test 2: Agent Swarm\n+    try:\n+        results['agent_swarm'] = test_agent_swarm()\n+        console.print(\"[green]‚úÖ Agent Swarm Test: PASSED[/green]\")\n+    except Exception as e:\n+        console.print(f\"[red]‚ùå Agent Swarm Test: FAILED - {str(e)}[/red]\")\n+        results['agent_swarm'] = None\n+\n+    console.print()\n+\n+    # Test 3: Collaborative Optimization\n+    try:\n+        results['collaborative_optimization'] = test_collaborative_optimization()\n+        console.print(\"[green]‚úÖ Collaborative Optimization Test: PASSED[/green]\")\n+    except Exception as e:\n+        console.print(f\"[red]‚ùå Collaborative Optimization Test: FAILED - {str(e)}[/red]\")\n+        results['collaborative_optimization'] = None\n+\n+    console.print()\n+\n+    # Test 4: Advanced Commands\n+    try:\n+        test_advanced_commands()\n+        console.print(\"[green]‚úÖ Advanced Commands Test: PASSED[/green]\")\n+    except Exception as e:\n+        console.print(f\"[red]‚ùå Advanced Commands Test: FAILED - {str(e)}[/red]\")\n+\n+    # Summary\n+    console.print(\"\\n\" + \"=\"*60)\n+    console.print(\"[bold blue]Test Summary:[/bold blue]\")\n+\n+    passed = sum(1 for result in results.values() if result is not None)\n+    total = len(results) + 1  # +1 for advanced commands\n+\n+    console.print(f\"Tests Passed: {passed + 1}/{total}\")\n+    console.print(f\"Success Rate: {((passed + 1)/total)*100:.1f}%\")\n+\n+    if results['quality_control']:\n+        console.print(f\"Quality Score: {results['quality_control'].metrics['quality_score']:.1f}/100\")\n+\n+    if results['agent_swarm']:\n+        console.print(f\"Agent Analysis Quality: {results['agent_swarm']['quality_synthesis']['overall_quality_score']:.1f}/100\")\n+\n+    console.print(\"\\nüéâ Advanced Forge Testing Complete!\")\n+\n+if __name__ == \"__main__\":\n+    run_comprehensive_test()\n"
                }
            ],
            "date": 1753291110329,
            "name": "Commit-0",
            "content": "#!/usr/bin/env python3\n\"\"\"\nTest Advanced Forge Features\nComprehensive testing of quality controls and DSPy agents\n\"\"\"\n\nimport json\nfrom pathlib import Path\n\nfrom rich.console import Console\nfrom rich.panel import Panel\n\nfrom dspy_ontology_agents import CollaborativeOntologyOptimizer, OntologyAgentSwarm\nfrom ontology_quality_control import OntologyQualityController\n\nconsole = Console()\n\ndef test_quality_control():\n    \"\"\"Test quality control system\"\"\"\n    console.print(Panel.fit(\n        \"[bold blue]Testing Quality Control System[/bold blue]\",\n        border_style=\"blue\"\n    ))\n\n    # Test with existing real-time ontologies\n    realtime_dir = Path(\"ontologies/generated/realtime\")\n    if not realtime_dir.exists():\n        console.print(\"[red]Real-time ontologies not found - run real-time generation first[/red]\")\n        return\n\n    qc = OntologyQualityController()\n\n    console.print(\"üîç Running comprehensive validation...\")\n    report = qc.validate_ontology_suite(uhft_dir, \"trading\")\n\n    console.print(f\"üìä Quality Score: {report.metrics['quality_score']:.1f}/100\")\n    console.print(f\"üî¥ Critical Issues: {report.critical_count}\")\n    console.print(f\"üü° Warnings: {report.warning_count}\")\n    console.print(f\"‚úÖ Passed: {'Yes' if report.passed else 'No'}\")\n\n    # Test optimization\n    if report.issues:\n        console.print(\"\\n‚ö° Testing ontology optimization...\")\n\n        core_files = list(uhft_dir.glob(\"*core*.ttl\"))\n        if core_files:\n            try:\n                optimized_content, optimizations = qc.optimize_ontology(\n                    core_files[0],\n                    \"trading\",\n                    {\"tick_compliance\": 8}\n                )\n\n                console.print(f\"üìà Applied {len(optimizations)} optimizations:\")\n                for opt in optimizations:\n                    console.print(f\"  ‚Ä¢ {opt}\")\n\n            except Exception as e:\n                console.print(f\"[red]Optimization failed: {str(e)}[/red]\")\n\n    return report\n\ndef test_agent_swarm():\n    \"\"\"Test multi-agent analysis system\"\"\"\n    console.print(Panel.fit(\n        \"[bold green]Testing Multi-Agent Swarm[/bold green]\",\n        border_style=\"green\"\n    ))\n\n    # Test with trading ontologies\n    trading_dir = Path(\"ontologies/meta_generated/trading\")\n    if not trading_dir.exists():\n        console.print(\"[red]Trading ontologies not found - generate first[/red]\")\n        return\n\n    swarm = OntologyAgentSwarm()\n\n    requirements = {\n        \"performance_requirements\": {\"tick_compliance\": 8},\n        \"compliance_standards\": [\"MiFID II\"],\n        \"domain_patterns\": {\"ultra_low_latency\": True},\n        \"hardware_constraints\": {\"target_latency_ns\": 100}\n    }\n\n    console.print(\"ü§ñ Running multi-agent analysis...\")\n    try:\n        analysis = swarm.analyze_ontology_suite(trading_dir, \"trading\", requirements)\n\n        console.print(f\"üéØ Domain Accuracy: {analysis['domain_analysis']['accuracy_score']:.1f}%\")\n        console.print(f\"‚ö° Performance Score: {analysis['performance_analysis']['performance_score']:.1f}%\")\n        console.print(f\"üìã Compliance Score: {analysis['compliance_analysis']['compliance_score']:.1f}%\")\n        console.print(f\"üèÜ Overall Quality: {analysis['quality_synthesis']['overall_quality_score']:.1f}%\")\n\n        # Show agent communications\n        console.print(f\"\\nüí¨ Agent Messages: {len(analysis['message_history'])}\")\n        for msg in analysis['message_history'][:3]:  # Show first 3\n            console.print(f\"  {msg['from_agent']} ‚Üí {msg['to_agent']}: {msg['content']}\")\n\n        # Generate collaboration report\n        report = swarm.generate_agent_collaboration_report()\n        report_file = Path(\"agent_collaboration_report.md\")\n        report_file.write_text(report)\n        console.print(f\"üìÑ Collaboration report saved to: {report_file}\")\n\n        return analysis\n\n    except Exception as e:\n        console.print(f\"[red]Agent swarm failed: {str(e)}[/red]\")\n        return None\n\ndef test_collaborative_optimization():\n    \"\"\"Test collaborative optimization\"\"\"\n    console.print(Panel.fit(\n        \"[bold yellow]Testing Collaborative Optimization[/bold yellow]\",\n        border_style=\"yellow\"\n    ))\n\n    trading_dir = Path(\"ontologies/meta_generated/trading\")\n    if not trading_dir.exists():\n        console.print(\"[red]Trading ontologies not found[/red]\")\n        return\n\n    optimizer = CollaborativeOntologyOptimizer()\n\n    requirements = {\n        \"performance_requirements\": {\"tick_compliance\": 8},\n        \"compliance_standards\": [\"MiFID II\"],\n        \"quality_threshold\": 90.0\n    }\n\n    console.print(\"üîÑ Running iterative optimization...\")\n    try:\n        optimization_result = optimizer.iterative_optimization(\n            trading_dir, \"trading\", requirements, max_iterations=2\n        )\n\n        console.print(f\"üéØ Iterations Completed: {optimization_result['iterations_completed']}\")\n        console.print(f\"üìà Final Quality Score: {optimization_result['final_quality_score']:.1f}%\")\n\n        # Show optimization history\n        for iteration in optimization_result['optimization_history']:\n            if 'error' not in iteration:\n                console.print(f\"  Iteration {iteration['iteration']}: \"\n                            f\"{iteration['quality_score_before']:.1f}% ‚Üí \"\n                            f\"{iteration['quality_score_after']:.1f}%\")\n\n        return optimization_result\n\n    except Exception as e:\n        console.print(f\"[red]Collaborative optimization failed: {str(e)}[/red]\")\n        return None\n\ndef test_advanced_commands():\n    \"\"\"Test advanced CLI commands\"\"\"\n    console.print(Panel.fit(\n        \"[bold magenta]Testing Advanced CLI Commands[/bold magenta]\",\n        border_style=\"magenta\"\n    ))\n\n    # Test validation command\n    console.print(\"üîç Testing validation command...\")\n\n    # Create test manifest for validation\n    test_dir = Path(\"test_ontologies\")\n    test_dir.mkdir(exist_ok=True)\n\n    # Create simple test ontology\n    test_ttl = test_dir / \"test.ttl\"\n    test_ttl.write_text(\"\"\"\n@prefix : <http://test.io#> .\n@prefix owl: <http://www.w3.org/2002/07/owl#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n\n:TestClass a owl:Class ;\n    rdfs:label \"Test Class\" .\n\n:testProperty a owl:DatatypeProperty ;\n    rdfs:domain :TestClass .\n\"\"\")\n\n    # Create manifest\n    manifest = {\n        \"domain\": \"test\",\n        \"name\": \"Test Ontology\",\n        \"performance_requirements\": {\"tick_compliance\": 8},\n        \"compliance_standards\": []\n    }\n\n    manifest_file = test_dir / \"manifest.json\"\n    with open(manifest_file, 'w') as f:\n        json.dump(manifest, f, indent=2)\n\n    console.print(f\"‚úÖ Created test ontology in {test_dir}\")\n\n    # Show what advanced commands would do\n    console.print(\"\\nüìã Available Advanced Commands:\")\n    commands = [\n        (\"validate\", \"Comprehensive quality validation\"),\n        (\"optimize\", \"DSPy-powered optimization\"),\n        (\"audit\", \"Compliance auditing\"),\n        (\"benchmark\", \"Advanced benchmarking\"),\n        (\"explain\", \"AI-powered explanation\"),\n        (\"compare\", \"Multi-dimensional comparison\"),\n        (\"deploy\", \"Quality-gated deployment\")\n    ]\n\n    for cmd, desc in commands:\n        console.print(f\"  ‚Ä¢ {cmd}: {desc}\")\n\ndef run_comprehensive_test():\n    \"\"\"Run comprehensive test suite\"\"\"\n    console.print(Panel.fit(\n        \"[bold red]üöÄ Advanced Forge Comprehensive Test Suite[/bold red]\",\n        border_style=\"red\"\n    ))\n\n    results = {}\n\n    # Test 1: Quality Control\n    try:\n        results['quality_control'] = test_quality_control()\n        console.print(\"[green]‚úÖ Quality Control Test: PASSED[/green]\")\n    except Exception as e:\n        console.print(f\"[red]‚ùå Quality Control Test: FAILED - {str(e)}[/red]\")\n        results['quality_control'] = None\n\n    console.print()\n\n    # Test 2: Agent Swarm\n    try:\n        results['agent_swarm'] = test_agent_swarm()\n        console.print(\"[green]‚úÖ Agent Swarm Test: PASSED[/green]\")\n    except Exception as e:\n        console.print(f\"[red]‚ùå Agent Swarm Test: FAILED - {str(e)}[/red]\")\n        results['agent_swarm'] = None\n\n    console.print()\n\n    # Test 3: Collaborative Optimization\n    try:\n        results['collaborative_optimization'] = test_collaborative_optimization()\n        console.print(\"[green]‚úÖ Collaborative Optimization Test: PASSED[/green]\")\n    except Exception as e:\n        console.print(f\"[red]‚ùå Collaborative Optimization Test: FAILED - {str(e)}[/red]\")\n        results['collaborative_optimization'] = None\n\n    console.print()\n\n    # Test 4: Advanced Commands\n    try:\n        test_advanced_commands()\n        console.print(\"[green]‚úÖ Advanced Commands Test: PASSED[/green]\")\n    except Exception as e:\n        console.print(f\"[red]‚ùå Advanced Commands Test: FAILED - {str(e)}[/red]\")\n\n    # Summary\n    console.print(\"\\n\" + \"=\"*60)\n    console.print(\"[bold blue]Test Summary:[/bold blue]\")\n\n    passed = sum(1 for result in results.values() if result is not None)\n    total = len(results) + 1  # +1 for advanced commands\n\n    console.print(f\"Tests Passed: {passed + 1}/{total}\")\n    console.print(f\"Success Rate: {((passed + 1)/total)*100:.1f}%\")\n\n    if results['quality_control']:\n        console.print(f\"Quality Score: {results['quality_control'].metrics['quality_score']:.1f}/100\")\n\n    if results['agent_swarm']:\n        console.print(f\"Agent Analysis Quality: {results['agent_swarm']['quality_synthesis']['overall_quality_score']:.1f}/100\")\n\n    console.print(\"\\nüéâ Advanced Forge Testing Complete!\")\n\nif __name__ == \"__main__\":\n    run_comprehensive_test()\n"
        }
    ]
}