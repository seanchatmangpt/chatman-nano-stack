#!/usr/bin/env python3
"""
K8s Inter-Service Communication Stress Test
Comprehensive stress testing for service mesh resilience and circuit breaker validation
"""

import asyncio
import aiohttp
import grpc
import time
import json
import random
import statistics
import psutil
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
from pathlib import Path
import concurrent.futures
import subprocess

@dataclass
class StressTestResult:
    """Stress test result data structure"""
    test_name: str
    test_duration_s: float
    total_requests: int
    successful_requests: int
    failed_requests: int
    peak_rps: float
    avg_rps: float
    peak_latency_ms: float
    avg_latency_ms: float
    circuit_breaker_triggered: bool
    resource_exhaustion_detected: bool
    service_recovery_time_s: float
    system_stability_score: float
    error_patterns: Dict[str, int]

class K8sInterServiceStressTest:
    """Comprehensive stress test suite for K8s inter-service communication"""
    
    def __init__(self):
        self.services = {
            'gateway': {
                'host': 'cns-gateway-service.cns-system.svc.cluster.local',
                'port': 8081,
                'protocol': 'http',
                'endpoints': ['/health', '/api/v1/protection/validate', '/api/v1/analytics/metrics']
            },
            'protection': {
                'host': 'cns-protection-service.cns-system.svc.cluster.local',
                'port': 8080,
                'protocol': 'grpc',
                'endpoints': ['health_check']
            },
            'analytics': {
                'host': 'cns-analytics-service.cns-system.svc.cluster.local',
                'port': 8082,
                'protocol': 'grpc',
                'endpoints': ['health_check']
            },
            'monitor': {
                'host': 'cns-monitor-service.cns-system.svc.cluster.local',
                'port': 8083,
                'protocol': 'http',
                'endpoints': ['/health', '/status', '/metrics']
            }
        }
        self.stress_test_results = []
        
    async def stress_test_load_spikes(self, duration_s: int = 300) -> StressTestResult:
        """Test service resilience under sudden load spikes"""
        print(f"üî• Running Load Spike Stress Test for {duration_s}s...")
        
        start_time = time.perf_counter()
        total_requests = 0
        successful_requests = 0
        failed_requests = 0
        latencies = []
        rps_measurements = []
        error_patterns = {}
        circuit_breaker_triggered = False
        resource_exhaustion_detected = False
        
        # Initial system resource baseline
        initial_cpu = psutil.cpu_percent()
        initial_memory = psutil.virtual_memory().percent
        
        async def load_spike_pattern():
            """Generate load spike pattern: low -> high -> low"""
            nonlocal total_requests, successful_requests, failed_requests
            nonlocal latencies, rps_measurements, circuit_breaker_triggered
            
            connector = aiohttp.TCPConnector(limit=500, limit_per_host=100)
            timeout = aiohttp.ClientTimeout(total=30)
            
            async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                
                # Phase 1: Normal load (30s)
                print("  Phase 1: Normal load...")
                await self._generate_load(session, 50, 30, "normal", 
                                        total_requests, successful_requests, failed_requests, 
                                        latencies, rps_measurements, error_patterns)
                
                # Phase 2: Spike load (60s) 
                print("  Phase 2: Spike load...")
                spike_results = await self._generate_load(session, 500, 60, "spike",
                                                        total_requests, successful_requests, failed_requests,
                                                        latencies, rps_measurements, error_patterns)
                
                # Check for circuit breaker activation
                if spike_results['error_rate'] > 50:
                    circuit_breaker_triggered = True
                
                # Phase 3: Recovery load (30s)
                print("  Phase 3: Recovery load...")
                await self._generate_load(session, 100, 30, "recovery",
                                        total_requests, successful_requests, failed_requests,
                                        latencies, rps_measurements, error_patterns)
                
                # Phase 4: Sustained high load (remaining time)
                remaining_time = duration_s - 120
                if remaining_time > 0:
                    print(f"  Phase 4: Sustained load for {remaining_time}s...")
                    await self._generate_load(session, 200, remaining_time, "sustained",
                                            total_requests, successful_requests, failed_requests,
                                            latencies, rps_measurements, error_patterns)
        
        await load_spike_pattern()
        
        total_time = time.perf_counter() - start_time
        
        # Check for resource exhaustion
        final_cpu = psutil.cpu_percent()
        final_memory = psutil.virtual_memory().percent
        
        if final_cpu > 90 or final_memory > 95:
            resource_exhaustion_detected = True
        
        # Calculate metrics
        peak_rps = max(rps_measurements) if rps_measurements else 0
        avg_rps = statistics.mean(rps_measurements) if rps_measurements else 0
        peak_latency = max(latencies) if latencies else 0
        avg_latency = statistics.mean(latencies) if latencies else 0
        
        # Calculate system stability score (0-100)
        error_rate = (failed_requests / total_requests * 100) if total_requests > 0 else 0
        latency_stability = max(0, 100 - (peak_latency - avg_latency) / avg_latency * 100) if avg_latency > 0 else 0
        throughput_stability = max(0, 100 - abs(peak_rps - avg_rps) / avg_rps * 100) if avg_rps > 0 else 0
        
        stability_score = (
            (100 - error_rate) * 0.4 +
            latency_stability * 0.3 +
            throughput_stability * 0.3
        )
        
        # Measure service recovery time
        recovery_time = await self._measure_service_recovery_time()
        
        return StressTestResult(
            test_name="load_spike_stress_test",
            test_duration_s=total_time,
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            peak_rps=peak_rps,
            avg_rps=avg_rps,
            peak_latency_ms=peak_latency,
            avg_latency_ms=avg_latency,
            circuit_breaker_triggered=circuit_breaker_triggered,
            resource_exhaustion_detected=resource_exhaustion_detected,
            service_recovery_time_s=recovery_time,
            system_stability_score=stability_score,
            error_patterns=error_patterns
        )
    
    async def _generate_load(self, session: aiohttp.ClientSession, target_rps: int, 
                           duration_s: int, phase_name: str, *counters) -> Dict[str, Any]:
        """Generate load at target RPS for specified duration"""
        
        requests_sent = 0
        errors_in_phase = 0
        phase_latencies = []
        
        end_time = time.perf_counter() + duration_s
        request_interval = 1.0 / target_rps if target_rps > 0 else 0.1
        
        while time.perf_counter() < end_time:
            batch_start = time.perf_counter()
            
            # Send batch of requests
            batch_size = min(target_rps // 10, 50)  # Adjust batch size based on target RPS
            tasks = []
            
            for _ in range(batch_size):
                service_name = random.choice(list(self.services.keys()))
                task = self._make_request(session, service_name)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            for result in results:
                requests_sent += 1
                if isinstance(result, Exception) or result is None:
                    errors_in_phase += 1
                else:
                    latency_ms, success = result
                    phase_latencies.append(latency_ms)
                    if not success:
                        errors_in_phase += 1
            
            # Maintain target RPS
            batch_duration = time.perf_counter() - batch_start
            sleep_time = max(0, request_interval * batch_size - batch_duration)
            if sleep_time > 0:
                await asyncio.sleep(sleep_time)
        
        error_rate = (errors_in_phase / requests_sent * 100) if requests_sent > 0 else 0
        
        return {
            'phase': phase_name,
            'requests_sent': requests_sent,
            'errors': errors_in_phase,
            'error_rate': error_rate,
            'avg_latency': statistics.mean(phase_latencies) if phase_latencies else 0
        }
    
    async def _make_request(self, session: aiohttp.ClientSession, service_name: str) -> Tuple[float, bool]:
        """Make a request to a specific service"""
        service = self.services[service_name]
        request_start = time.perf_counter()
        
        try:
            if service['protocol'] == 'http':
                endpoint = random.choice(service['endpoints'])
                url = f"http://{service['host']}:{service['port']}{endpoint}"
                
                if endpoint.startswith('/api/'):
                    # POST request for API endpoints
                    payload = {
                        'request_id': f"stress_{int(time.time() * 1000000)}",
                        'data': 'stress_test_payload'
                    }
                    async with session.post(url, json=payload) as response:
                        await response.text()
                        latency = (time.perf_counter() - request_start) * 1000
                        return latency, response.status in [200, 202, 204]
                else:
                    # GET request for health endpoints
                    async with session.get(url) as response:
                        await response.text()
                        latency = (time.perf_counter() - request_start) * 1000
                        return latency, response.status in [200, 204]
            
            else:  # gRPC
                # For gRPC, we'll simulate the request time
                await asyncio.sleep(random.uniform(0.001, 0.01))  # Simulate gRPC call
                latency = (time.perf_counter() - request_start) * 1000
                return latency, True
                
        except Exception:
            latency = (time.perf_counter() - request_start) * 1000
            return latency, False
    
    async def _measure_service_recovery_time(self) -> float:
        """Measure time for services to recover to normal operation"""
        print("  Measuring service recovery time...")
        
        recovery_start = time.perf_counter()
        max_recovery_time = 60  # Maximum time to wait for recovery
        
        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
            while time.perf_counter() - recovery_start < max_recovery_time:
                all_healthy = True
                
                for service_name, service_config in self.services.items():
                    if service_config['protocol'] == 'http':
                        try:
                            url = f"http://{service_config['host']}:{service_config['port']}/health"
                            async with session.get(url) as response:
                                if response.status not in [200, 204]:
                                    all_healthy = False
                                    break
                        except:
                            all_healthy = False
                            break
                
                if all_healthy:
                    return time.perf_counter() - recovery_start
                
                await asyncio.sleep(1)
        
        return max_recovery_time  # Recovery took longer than max time
    
    async def stress_test_circuit_breaker(self) -> StressTestResult:
        """Test circuit breaker functionality under sustained failures"""
        print("üî• Running Circuit Breaker Stress Test...")
        
        start_time = time.perf_counter()
        total_requests = 0
        successful_requests = 0
        failed_requests = 0
        latencies = []
        circuit_breaker_triggered = False
        error_patterns = {'timeout': 0, 'connection_error': 0, 'server_error': 0}
        
        # Simulate service failure by overwhelming with requests
        connector = aiohttp.TCPConnector(limit=1000, limit_per_host=200)
        timeout = aiohttp.ClientTimeout(total=5)  # Short timeout to trigger failures
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            
            # Phase 1: Overwhelm services to trigger circuit breaker (60s)
            print("  Phase 1: Overwhelming services...")
            for _ in range(60):
                batch_tasks = []
                
                # Send high-frequency requests
                for _ in range(100):  # 100 req/s
                    service_name = random.choice(['gateway', 'monitor'])  # Focus on HTTP services
                    service = self.services[service_name]
                    url = f"http://{service['host']}:{service['port']}/health"
                    
                    batch_tasks.append(self._make_circuit_breaker_request(session, url))
                
                results = await asyncio.gather(*batch_tasks, return_exceptions=True)
                
                for result in results:
                    total_requests += 1
                    if isinstance(result, Exception):
                        failed_requests += 1
                        error_patterns['connection_error'] += 1
                    else:
                        latency, success, error_type = result
                        latencies.append(latency)
                        if success:
                            successful_requests += 1
                        else:
                            failed_requests += 1
                            error_patterns[error_type] += 1
                
                # Check if circuit breaker is triggered (high failure rate)
                current_error_rate = (failed_requests / total_requests * 100) if total_requests > 0 else 0
                if current_error_rate > 50:
                    circuit_breaker_triggered = True
                
                await asyncio.sleep(1)
            
            # Phase 2: Allow recovery (30s)
            print("  Phase 2: Allowing service recovery...")
            await asyncio.sleep(30)
            
            # Phase 3: Test recovery (30s)
            print("  Phase 3: Testing service recovery...")
            recovery_successful = 0
            recovery_attempts = 30
            
            for _ in range(recovery_attempts):
                try:
                    url = f"http://{self.services['gateway']['host']}:{self.services['gateway']['port']}/health"
                    async with session.get(url) as response:
                        if response.status in [200, 204]:
                            recovery_successful += 1
                except:
                    pass
                
                await asyncio.sleep(1)
        
        total_time = time.perf_counter() - start_time
        
        # Calculate metrics
        avg_latency = statistics.mean(latencies) if latencies else 0
        peak_latency = max(latencies) if latencies else 0
        recovery_rate = (recovery_successful / recovery_attempts * 100) if recovery_attempts > 0 else 0
        
        # System stability score based on circuit breaker effectiveness
        stability_score = (
            (50 if circuit_breaker_triggered else 0) +  # Circuit breaker triggered as expected
            (recovery_rate / 2)  # Recovery effectiveness
        )
        
        return StressTestResult(
            test_name="circuit_breaker_stress_test",
            test_duration_s=total_time,
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            peak_rps=0,  # Not measured in this test
            avg_rps=total_requests / total_time,
            peak_latency_ms=peak_latency,
            avg_latency_ms=avg_latency,
            circuit_breaker_triggered=circuit_breaker_triggered,
            resource_exhaustion_detected=False,
            service_recovery_time_s=30,  # Fixed recovery time in test
            system_stability_score=stability_score,
            error_patterns=error_patterns
        )
    
    async def _make_circuit_breaker_request(self, session: aiohttp.ClientSession, url: str) -> Tuple[float, bool, str]:
        """Make request for circuit breaker testing"""
        request_start = time.perf_counter()
        
        try:
            async with session.get(url) as response:
                latency = (time.perf_counter() - request_start) * 1000
                if response.status in [200, 204]:
                    return latency, True, 'success'
                else:
                    return latency, False, 'server_error'
                    
        except asyncio.TimeoutError:
            latency = (time.perf_counter() - request_start) * 1000
            return latency, False, 'timeout'
        except Exception:
            latency = (time.perf_counter() - request_start) * 1000
            return latency, False, 'connection_error'
    
    async def stress_test_resource_exhaustion(self) -> StressTestResult:
        """Test service behavior under resource exhaustion"""
        print("üî• Running Resource Exhaustion Stress Test...")
        
        start_time = time.perf_counter()
        total_requests = 0
        successful_requests = 0
        failed_requests = 0
        resource_exhaustion_detected = False
        
        # Monitor system resources
        initial_cpu = psutil.cpu_percent()
        initial_memory = psutil.virtual_memory().percent
        
        # Generate memory and CPU intensive workload
        connector = aiohttp.TCPConnector(limit=2000, limit_per_host=500)
        timeout = aiohttp.ClientTimeout(total=60)
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            
            # Create large number of concurrent connections
            print("  Creating intensive workload...")
            
            tasks = []
            for i in range(1000):  # Create 1000 concurrent requests
                service_name = random.choice(list(self.services.keys()))
                if self.services[service_name]['protocol'] == 'http':
                    url = f"http://{self.services[service_name]['host']}:{self.services[service_name]['port']}/health"
                    tasks.append(self._resource_intensive_request(session, url, i))
            
            # Execute all requests concurrently
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for result in results:
                total_requests += 1
                if isinstance(result, Exception):
                    failed_requests += 1
                else:
                    success = result
                    if success:
                        successful_requests += 1
                    else:
                        failed_requests += 1
        
        total_time = time.perf_counter() - start_time
        
        # Check for resource exhaustion
        final_cpu = psutil.cpu_percent()
        final_memory = psutil.virtual_memory().percent
        
        if final_cpu > 95 or final_memory > 90:
            resource_exhaustion_detected = True
        
        # Calculate stability score based on graceful degradation
        error_rate = (failed_requests / total_requests * 100) if total_requests > 0 else 0
        graceful_degradation_score = max(0, 100 - error_rate)
        
        return StressTestResult(
            test_name="resource_exhaustion_stress_test",
            test_duration_s=total_time,
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            peak_rps=0,
            avg_rps=total_requests / total_time,
            peak_latency_ms=0,
            avg_latency_ms=0,
            circuit_breaker_triggered=False,
            resource_exhaustion_detected=resource_exhaustion_detected,
            service_recovery_time_s=0,
            system_stability_score=graceful_degradation_score,
            error_patterns={'resource_exhaustion': failed_requests}
        )
    
    async def _resource_intensive_request(self, session: aiohttp.ClientSession, url: str, request_id: int) -> bool:
        """Make resource-intensive request"""
        try:
            # Add delay to simulate processing time
            await asyncio.sleep(random.uniform(0.1, 0.5))
            
            async with session.get(url) as response:
                await response.text()  # Ensure response is fully read
                return response.status in [200, 204]
                
        except Exception:
            return False
    
    def get_kubernetes_metrics(self) -> Dict[str, Any]:
        """Get Kubernetes cluster metrics during stress test"""
        try:
            # Get pod metrics
            pod_metrics = subprocess.run([
                'kubectl', 'top', 'pods', '-n', 'cns-system', '--no-headers'
            ], capture_output=True, text=True, timeout=30)
            
            # Get node metrics
            node_metrics = subprocess.run([
                'kubectl', 'top', 'nodes', '--no-headers'
            ], capture_output=True, text=True, timeout=30)
            
            # Parse metrics (simplified)
            metrics = {
                'pod_metrics_available': pod_metrics.returncode == 0,
                'node_metrics_available': node_metrics.returncode == 0,
                'cluster_accessible': True
            }
            
            if pod_metrics.returncode == 0:
                pod_lines = pod_metrics.stdout.strip().split('\n')
                metrics['pod_count'] = len([line for line in pod_lines if line.strip()])
            
            return metrics
            
        except Exception as e:
            return {
                'pod_metrics_available': False,
                'node_metrics_available': False, 
                'cluster_accessible': False,
                'error': str(e)
            }
    
    async def run_comprehensive_stress_tests(self) -> Dict[str, Any]:
        """Run comprehensive stress test suite"""
        print("üî• RUNNING COMPREHENSIVE K8S INTER-SERVICE STRESS TESTS")
        print("=" * 80)
        
        start_time = time.perf_counter()
        all_results = []
        
        # Get initial Kubernetes metrics
        initial_k8s_metrics = self.get_kubernetes_metrics()
        
        # Test 1: Load Spike Stress Test
        print("\nüîç Running Load Spike Stress Test...")
        load_spike_result = await self.stress_test_load_spikes(300)  # 5 minutes
        all_results.append(load_spike_result)
        print(f"  Peak RPS: {load_spike_result.peak_rps:.1f}")
        print(f"  Circuit Breaker: {'‚úÖ Triggered' if load_spike_result.circuit_breaker_triggered else '‚ùå Not Triggered'}")
        print(f"  Stability Score: {load_spike_result.system_stability_score:.1f}")
        
        # Test 2: Circuit Breaker Stress Test
        print("\nüîç Running Circuit Breaker Stress Test...")
        circuit_breaker_result = await self.stress_test_circuit_breaker()
        all_results.append(circuit_breaker_result)
        print(f"  Circuit Breaker: {'‚úÖ Triggered' if circuit_breaker_result.circuit_breaker_triggered else '‚ùå Not Triggered'}")
        print(f"  Recovery Time: {circuit_breaker_result.service_recovery_time_s:.1f}s")
        
        # Test 3: Resource Exhaustion Stress Test
        print("\nüîç Running Resource Exhaustion Stress Test...")
        resource_exhaustion_result = await self.stress_test_resource_exhaustion()
        all_results.append(resource_exhaustion_result)
        print(f"  Resource Exhaustion: {'‚úÖ Detected' if resource_exhaustion_result.resource_exhaustion_detected else '‚ùå Not Detected'}")
        print(f"  Graceful Degradation: {resource_exhaustion_result.system_stability_score:.1f}")
        
        total_time = time.perf_counter() - start_time
        
        # Get final Kubernetes metrics
        final_k8s_metrics = self.get_kubernetes_metrics()
        
        # Calculate aggregate metrics
        total_requests = sum(r.total_requests for r in all_results)
        total_successful = sum(r.successful_requests for r in all_results)
        overall_stability = statistics.mean([r.system_stability_score for r in all_results])
        
        # Evaluate system resilience
        resilience_score = (
            (50 if any(r.circuit_breaker_triggered for r in all_results) else 0) +
            (30 if overall_stability >= 70 else 0) +
            (20 if total_successful / total_requests >= 0.8 else 0) if total_requests > 0 else 0
        )
        
        summary = {
            'stress_test_summary': {
                'total_execution_time_s': total_time,
                'total_requests_executed': total_requests,
                'total_successful_requests': total_successful,
                'overall_success_rate_percent': (total_successful / total_requests * 100) if total_requests > 0 else 0,
                'overall_stability_score': overall_stability,
                'system_resilience_score': resilience_score,
                'tests_executed': len(all_results),
                'timestamp': time.time()
            },
            'detailed_results': [
                {
                    'test_name': r.test_name,
                    'duration_s': r.test_duration_s,
                    'requests': r.total_requests,
                    'success_rate_percent': (r.successful_requests / r.total_requests * 100) if r.total_requests > 0 else 0,
                    'peak_rps': r.peak_rps,
                    'avg_rps': r.avg_rps,
                    'circuit_breaker_triggered': r.circuit_breaker_triggered,
                    'resource_exhaustion_detected': r.resource_exhaustion_detected,
                    'stability_score': r.system_stability_score,
                    'error_patterns': r.error_patterns
                }
                for r in all_results
            ],
            'kubernetes_metrics': {
                'initial': initial_k8s_metrics,
                'final': final_k8s_metrics
            },
            'resilience_evaluation': {
                'circuit_breaker_effectiveness': any(r.circuit_breaker_triggered for r in all_results),
                'resource_exhaustion_handling': any(r.resource_exhaustion_detected for r in all_results),
                'service_recovery_capability': max([r.service_recovery_time_s for r in all_results if r.service_recovery_time_s > 0], default=0) < 60,
                'overall_resilience_rating': 'EXCELLENT' if resilience_score >= 80 else 'GOOD' if resilience_score >= 60 else 'NEEDS_IMPROVEMENT'
            }
        }
        
        print(f"\nüìä STRESS TEST SUMMARY")
        print("=" * 50)
        print(f"Total Requests: {total_requests:,}")
        print(f"Success Rate: {summary['stress_test_summary']['overall_success_rate_percent']:.1f}%")
        print(f"Stability Score: {overall_stability:.1f}")
        print(f"Resilience Score: {resilience_score:.1f}")
        print(f"Overall Rating: {summary['resilience_evaluation']['overall_resilience_rating']}")
        
        return summary

async def main():
    """Execute the comprehensive stress test suite"""
    stress_tester = K8sInterServiceStressTest()
    results = await stress_tester.run_comprehensive_stress_tests()
    
    # Save results
    results_file = Path("k8s_interservice_stress_test_results.json")
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nüíæ Results saved to: {results_file}")
    
    # Evaluate stress test success
    resilience_score = results['stress_test_summary']['system_resilience_score']
    success_rate = results['stress_test_summary']['overall_success_rate_percent']
    
    if resilience_score >= 70 and success_rate >= 70:
        print("üéâ K8S INTER-SERVICE STRESS TESTS PASSED")
        return 0
    else:
        print("‚ö†Ô∏è K8S INTER-SERVICE STRESS TESTS FAILED")
        print(f"  Resilience Score: {resilience_score:.1f} (target: ‚â•70)")
        print(f"  Success Rate: {success_rate:.1f}% (target: ‚â•70%)")
        return 1

if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)